% This file was created with JabRef 2.10.
% Encoding: UTF-8

@article{fourier_feature_networks,
  year      = {2020},
  title     = {{Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains}},
  author    = {Tancik, Matthew and Srinivasan, Pratul P and Mildenhall, Ben and Fridovich-Keil, Sara and Raghavan, Nithin and Singhal, Utkarsh and Ramamoorthi, Ravi and Barron, Jonathan T and Ng, Ren},
  journal   = {arXiv},
  eprint    = {2006.10739},
  abstract  = {{We show that passing input points through a simple Fourier feature mapping enables a multilayer perceptron (MLP) to learn high-frequency functions in low-dimensional problem domains. These results shed light on recent advances in computer vision and graphics that achieve state-of-the-art results by using MLPs to represent complex 3D objects and scenes. Using tools from the neural tangent kernel (NTK) literature, we show that a standard MLP fails to learn high frequencies both in theory and in practice. To overcome this spectral bias, we use a Fourier feature mapping to transform the effective NTK into a stationary kernel with a tunable bandwidth. We suggest an approach for selecting problem-specific Fourier features that greatly improves the performance of MLPs for low-dimensional regression tasks relevant to the computer vision and graphics communities.}},
  note      = {Image Parameterization with Fourier Transform + MLP https://bmild.github.io/fourfeat/},
  keywords  = {},
  local-url = {file://localhost/Users/Ryan/Documents/Papers%20Library/Tancik-Fourier%20Features%20Let%20Networks%20Learn%20High%20Frequency%20Functions%20in%20Low%20Dimensional%20Domains-2020-arXiv.pdf}
}